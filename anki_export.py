#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Ankiå¯¼å‡ºæ¨¡å—
å°†å•è¯å­¦ä¹ ä¿¡æ¯å’ŒçŸ­æ–‡å¯¼å‡ºä¸ºAnkiå¡ç‰‡
"""

import sqlite3
import json
import csv
import os
import re
import random
from datetime import datetime
from typing import List, Dict, Any, Optional
from html import escape
import genanki


class AnkiExporter:
    """Ankiå¯¼å‡ºå™¨"""

    def __init__(self, db_path: str = "toefl_words.db"):
        """
        åˆå§‹åŒ–Ankiå¯¼å‡ºå™¨

        Args:
            db_path: æ•°æ®åº“æ–‡ä»¶è·¯å¾„
        """
        self.db_path = db_path

        # å®šä¹‰Ankiå¡ç‰‡æ¨¡å‹
        self.word_model = self._create_word_model()
        self.essay_model = self._create_essay_model()

    def _create_word_model(self) -> genanki.Model:
        """åˆ›å»ºå•è¯å¡ç‰‡æ¨¡å‹"""
        return genanki.Model(
            1607392319,  # æ¨¡å‹ID
            "TOEFL Word Model",
            fields=[
                {"name": "Word"},
                {"name": "Content"},
                {"name": "CardType"},
            ],
            templates=[
                {
                    "name": "Word Recognition",
                    "qfmt": """
                        <div class="card-front word-recognition">
                            <h2 class="word">{{Word}}</h2>
                            <div class="hint">è¯·å›æƒ³è¿™ä¸ªå•è¯çš„æ„æ€</div>
                        </div>
                    """,
                    "afmt": """
                        <div class="card-back">
                            <h2 class="word">{{Word}}</h2>
                            {{Content}}
                        </div>
                    """,
                },
            ],
            css=self._get_card_css(),
        )

    def _create_essay_model(self) -> genanki.Model:
        """åˆ›å»ºçŸ­æ–‡å¡ç‰‡æ¨¡å‹"""
        return genanki.Model(
            1607392320,  # æ¨¡å‹ID
            "TOEFL Essay Model",
            fields=[
                {"name": "Title"},
                {"name": "EnglishContent"},
                {"name": "ChineseContent"},
                {"name": "CardType"},
                {"name": "Words"},
            ],
            templates=[
                {
                    "name": "Essay Translation",
                    "qfmt": """
                        <div class="card-front essay-translation">
                            <h3>{{Title}}</h3>
                            <div class="english-text">{{EnglishContent}}</div>
                            {{#Words}}
                            <div class="essay-words">
                                <strong>ç›¸å…³å•è¯:</strong> {{Words}}
                            </div>
                            {{/Words}}
                            <div class="hint">è¯·ç¿»è¯‘è¿™æ®µè‹±æ–‡</div>
                        </div>
                    """,
                    "afmt": """
                        <div class="card-back">
                            <h3>{{Title}}</h3>
                            <div class="translation-pair">
                                <div class="english">
                                    <h4>è‹±æ–‡åŸæ–‡:</h4>
                                    <p>{{EnglishContent}}</p>
                                </div>
                                <div class="chinese">
                                    <h4>ä¸­æ–‡ç¿»è¯‘:</h4>
                                    <p>{{ChineseContent}}</p>
                                </div>
                            </div>
                            {{#Words}}
                            <div class="essay-words">
                                <strong>ç›¸å…³å•è¯:</strong> {{Words}}
                            </div>
                            {{/Words}}
                        </div>
                    """,
                },
                {
                    "name": "Essay Reverse",
                    "qfmt": """
                        <div class="card-front essay-reverse">
                            <h3>{{Title}}</h3>
                            <div class="chinese-text">{{ChineseContent}}</div>
                            {{#Words}}
                            <div class="essay-words">
                                <strong>ç›¸å…³å•è¯:</strong> {{Words}}
                            </div>
                            {{/Words}}
                            <div class="hint">è¯·æ ¹æ®ä¸­æ–‡ç¿»è¯‘å›æƒ³è‹±æ–‡åŸæ–‡</div>
                        </div>
                    """,
                    "afmt": """
                        <div class="card-back">
                            <h3>{{Title}}</h3>
                            <div class="translation-pair">
                                <div class="chinese">
                                    <h4>ä¸­æ–‡ç¿»è¯‘:</h4>
                                    <p>{{ChineseContent}}</p>
                                </div>
                                <div class="english">
                                    <h4>è‹±æ–‡åŸæ–‡:</h4>
                                    <p>{{EnglishContent}}</p>
                                </div>
                            </div>
                            {{#Words}}
                            <div class="essay-words">
                                <strong>ç›¸å…³å•è¯:</strong> {{Words}}
                            </div>
                            {{/Words}}
                        </div>
                    """,
                },
            ],
            css=self._get_card_css(),
        )

    def _get_card_css(self) -> str:
        """è·å–å¡ç‰‡CSSæ ·å¼"""
        return """
/* TOEFLå•è¯å¡ç‰‡ - æç®€è®¾è®¡ */

.card {
    font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;
    line-height: 1.5;
    color: #333;
    padding: 20px;
    max-width: 600px;
    margin: 0 auto;
}

/* æ­£é¢å¡ç‰‡ */
.card-front {
    text-align: center;
    padding: 40px 20px;
}

.word {
    font-size: 2.5em;
    font-weight: 300;
    color: #2c3e50;
    margin-bottom: 20px;
    letter-spacing: 1px;
}

.hint {
    color: #666;
    font-size: 16px;
    margin-top: 30px;
}

/* èƒŒé¢å¡ç‰‡å†…å®¹ */
.card-back {
    padding: 20px;
}

.word-content {
    line-height: 1.6;
}

.word-content > div {
    margin-bottom: 15px;
}

.word-content > div:last-child {
    margin-bottom: 0;
}

/* éŸ³æ ‡å’Œè¯æ€§è¡Œ */
.phonetic-line {
    font-size: 18px;
    margin-bottom: 20px;
    padding-bottom: 15px;
    border-bottom: 1px solid #eee;
}

.phonetic {
    color: #e74c3c;
    font-family: 'Times New Roman', serif;
    font-size: 18px;
    margin-right: 15px;
}

.pos {
    color: #7f8c8d;
    font-style: italic;
    font-size: 16px;
    font-weight: 500;
}

.pronunciation {
    color: #9b59b6;
    font-size: 14px;
    margin-left: 10px;
}

/* ç¿»è¯‘ */
.meanings {
    font-size: 20px;
    font-weight: 500;
    color: #2c3e50;
    margin-bottom: 20px;
    line-height: 1.4;
}

/* è¯æ ¹ */
.etymology {
    color: #666;
    font-size: 14px;
    font-style: italic;
    margin-bottom: 15px;
    padding-left: 10px;
    border-left: 2px solid #ddd;
}

.etymology::before {
    content: "è¯æ ¹: ";
    color: #7f8c8d;
    font-weight: 500;
    font-style: normal;
}

/* çŸ­è¯­ */
.phrases {
    font-size: 16px;
    color: #555;
    margin-bottom: 15px;
}

.phrases::before {
    content: "çŸ­è¯­: ";
    color: #7f8c8d;
    font-weight: 500;
}

.phrase-item {
    margin-bottom: 8px;
}

.phrase-item:last-child {
    margin-bottom: 0;
}

/* ä¾‹å¥ */
.examples {
    font-size: 15px;
    color: #555;
    line-height: 1.6;
}

.examples::before {
    content: "ä¾‹å¥:";
    color: #7f8c8d;
    font-weight: 500;
    display: block;
    margin-bottom: 8px;
}

.example-item {
    margin-bottom: 8px;
}

.example-item:last-child {
    margin-bottom: 0;
}

.examples small {
    color: #888;
    font-size: 13px;
    display: block;
    margin-top: 2px;
    margin-bottom: 0;
}

/* é”™è¯¯ä¿¡æ¯ */
.error {
    color: #e74c3c;
    text-align: center;
    padding: 20px;
    font-style: italic;
}

/* æ‹¼å†™å¡ç‰‡ */
.spelling-hint {
    padding: 30px;
    text-align: center;
    border: 2px dashed #ddd;
    border-radius: 8px;
}

.meaning {
    font-size: 24px;
    color: #2c3e50;
    margin: 20px 0;
    font-weight: 500;
}

.spelling-answer {
    background: linear-gradient(135deg, #3498db, #2980b9);
    color: white;
    padding: 20px;
    border-radius: 8px;
    text-align: center;
    font-size: 2.2em;
    font-weight: 300;
    letter-spacing: 2px;
}

/* åå‘å¡ç‰‡ */
.chinese-meaning {
    font-size: 28px;
    color: #2c3e50;
    text-align: center;
    padding: 30px;
    border: 2px solid #ecf0f1;
    border-radius: 8px;
    margin: 20px 0;
}

.reverse-answer {
    background: linear-gradient(135deg, #3498db, #2980b9);
    color: white;
    padding: 20px;
    border-radius: 8px;
    text-align: center;
    font-size: 2.2em;
    font-weight: 300;
    letter-spacing: 2px;
}

/* çŸ­æ–‡å¡ç‰‡ */
.english-text, .chinese-text {
    padding: 20px;
    line-height: 1.8;
    font-size: 16px;
    border-left: 3px solid #3498db;
    margin: 20px 0;
}

.translation-pair > div {
    margin-bottom: 20px;
    padding: 15px;
    border-radius: 5px;
}

.english {
    border-left: 3px solid #3498db;
}

.chinese {
    border-left: 3px solid #f39c12;
}

/* å¡«ç©ºå¡ç‰‡ */
.cloze-text {
    padding: 20px;
    line-height: 1.8;
    font-size: 16px;
    border-left: 3px solid #e74c3c;
    margin: 20px 0;
}

.blank {
    display: inline-block;
    min-width: 80px;
    height: 20px;
    border-bottom: 2px solid #e74c3c;
    margin: 0 3px;
}

.word-bank {
    padding: 15px;
    border-left: 3px solid #17a2b8;
    margin-top: 20px;
    font-size: 14px;
    color: #666;
}

.complete-text {
    padding: 20px;
    line-height: 1.8;
    border-left: 3px solid #28a745;
    margin: 20px 0;
}

.blanked-words {
    padding: 15px;
    border-left: 3px solid #ffc107;
    margin-top: 20px;
    font-weight: 500;
    color: #856404;
}

/* å“åº”å¼ */
@media (max-width: 768px) {
    .card {
        padding: 15px;
    }
    
    .word {
        font-size: 2em;
    }
    
    .meanings {
        font-size: 18px;
    }
    
    .card-front {
        padding: 30px 15px;
    }
}
"""

    def get_database_connection(self) -> sqlite3.Connection:
        """è·å–æ•°æ®åº“è¿æ¥"""
        conn = sqlite3.connect(self.db_path)
        conn.row_factory = sqlite3.Row
        return conn

    def _format_learning_content(self, content: Dict[str, Any], word: str = "") -> str:
        """
        æ ¼å¼åŒ–å­¦ä¹ å†…å®¹ä¸ºHTML - æç®€å¹²å‡€è®¾è®¡

        Args:
            content: å­¦ä¹ å†…å®¹å­—å…¸
            word: å•è¯ï¼ˆç”¨äºå‘éŸ³åŠŸèƒ½ï¼‰

        Returns:
            str: æ ¼å¼åŒ–çš„HTMLå†…å®¹
        """
        if not content or "error" in content:
            return "<div class='error'>å­¦ä¹ å†…å®¹ç”Ÿæˆå¤±è´¥</div>"

        sections = []

        # 1. éŸ³æ ‡å’Œè¯æ€§è¡Œï¼ˆä¿ç•™éŸ³æ ‡ï¼Œåˆ é™¤å‘éŸ³åŠŸèƒ½ï¼‰
        phonetic_line = []

        # å¤„ç†éŸ³æ ‡
        if "phonetic" in content:
            phonetic = content["phonetic"]
            if isinstance(phonetic, dict):
                # ä»å­—å…¸ä¸­æå–éŸ³æ ‡
                phonetic_parts = []
                if "UK" in phonetic and phonetic["UK"]:
                    phonetic_parts.append(f"è‹± {phonetic['UK']}")
                if "US" in phonetic and phonetic["US"]:
                    phonetic_parts.append(f"ç¾ {phonetic['US']}")
                if phonetic_parts:
                    phonetic_text = " ".join(phonetic_parts)
                    phonetic_line.append(
                        f'<span class="phonetic">{escape(phonetic_text)}</span>'
                    )
            elif isinstance(phonetic, str) and phonetic.strip():
                clean_phonetic = phonetic.strip("{}").strip()
                if clean_phonetic:
                    phonetic_line.append(
                        f'<span class="phonetic">{escape(clean_phonetic)}</span>'
                    )

        # å¤„ç†è¯æ€§
        if "part_of_speech" in content:
            pos = content["part_of_speech"]
            if isinstance(pos, list):
                pos_clean = [
                    p.strip("{}").strip() for p in pos if p.strip("{}").strip()
                ]
                if pos_clean:
                    phonetic_line.append(
                        f'<span class="pos">{escape(" ".join(pos_clean))}</span>'
                    )
            elif isinstance(pos, str) and pos.strip():
                pos_clean = pos.strip("{}").strip()
                if pos_clean:
                    phonetic_line.append(
                        f'<span class="pos">{escape(pos_clean)}</span>'
                    )

        # å¤„ç†å‘éŸ³æç¤ºï¼ˆåœ†ç‚¹åˆ†å‰²çš„å•è¯å‘éŸ³ï¼‰
        if "pronunciation" in content:
            pronunciation_text = (
                content["pronunciation"].strip("{}").strip()
                if isinstance(content["pronunciation"], str)
                else str(content["pronunciation"])
            )
            if pronunciation_text:
                phonetic_line.append(
                    f'<span class="pronunciation">{escape(pronunciation_text)}</span>'
                )

        if phonetic_line:
            sections.append(
                f'<div class="phonetic-line">{" ".join(phonetic_line)}</div>'
            )

        # 2. ç¿»è¯‘
        if "translations" in content:
            translations = content["translations"]
            if isinstance(translations, list):
                clean_translations = [
                    str(t).strip("{}").strip()
                    for t in translations
                    if str(t).strip("{}").strip()
                ]
                if clean_translations:
                    sections.append(
                        f'<div class="meanings">{escape(" / ".join(clean_translations))}</div>'
                    )
            elif isinstance(translations, str) and translations.strip():
                clean_trans = translations.strip("{}").strip()
                if clean_trans:
                    sections.append(
                        f'<div class="meanings">{escape(clean_trans)}</div>'
                    )

        # 3. è¯æ ¹è¯ç¼€ï¼ˆå¦‚æœæœ‰ï¼‰
        if "etymology" in content and content["etymology"]:
            etymology = str(content["etymology"]).strip("{}").strip()
            if etymology:
                sections.append(f'<div class="etymology">{escape(etymology)}</div>')

        # 4. çŸ­è¯­
        if "common_phrases" in content:
            phrases = content["common_phrases"]
            if isinstance(phrases, list):
                phrase_items = []
                for phrase_item in phrases:
                    if isinstance(phrase_item, dict):
                        # ä»å­—å…¸ä¸­æå–çŸ­è¯­å’Œç¿»è¯‘
                        phrase_text = phrase_item.get("phrase", "").strip()
                        translation = phrase_item.get("translation", "").strip()
                        if phrase_text:
                            if translation:
                                phrase_items.append(f"{phrase_text} {translation}")
                            else:
                                phrase_items.append(phrase_text)
                    elif isinstance(phrase_item, str):
                        clean_phrase = phrase_item.strip("{}").strip()
                        if clean_phrase:
                            phrase_items.append(clean_phrase)

                if phrase_items:
                    # ä¸ºæ¯ä¸ªçŸ­è¯­æ·»åŠ å•ç‹¬çš„divåŒ…è£…ï¼Œä¾¿äºæ§åˆ¶é—´è·ï¼ˆå’Œä¾‹å¥é€»è¾‘ä¸€æ ·ï¼‰
                    phrase_divs = []
                    for item in phrase_items:
                        phrase_divs.append(f'<div class="phrase-item">{item}</div>')
                    phrases_html = "".join(phrase_divs)
                    sections.append(f'<div class="phrases">{phrases_html}</div>')

        # 5. ä¾‹å¥
        if "examples" in content:
            examples = content["examples"]
            if isinstance(examples, list):
                example_items = []
                for example_item in examples[:2]:  # åªæ˜¾ç¤ºå‰2ä¸ªä¾‹å¥
                    if isinstance(example_item, dict):
                        # ä»å­—å…¸ä¸­æå–ä¾‹å¥å’Œç¿»è¯‘
                        sentence = example_item.get("sentence", "").strip()
                        translation = example_item.get("translation", "").strip()
                        if sentence:
                            if translation:
                                example_items.append(
                                    f"{sentence}<br><small>{translation}</small>"
                                )
                            else:
                                example_items.append(sentence)
                    elif isinstance(example_item, str):
                        clean_example = example_item.strip("{}").strip()
                        if clean_example:
                            example_items.append(clean_example)

                if example_items:
                    # ä¸ºæ¯ä¸ªä¾‹å¥æ·»åŠ å•ç‹¬çš„divåŒ…è£…ï¼Œä¾¿äºæ§åˆ¶é—´è·
                    example_divs = []
                    for item in example_items:
                        example_divs.append(f'<div class="example-item">{item}</div>')
                    examples_html = "".join(example_divs)
                    sections.append(f'<div class="examples">{examples_html}</div>')

        return f'<div class="word-content">{"".join(sections)}</div>'

    def _create_word_recognition_card(
        self, word: str, content: Dict[str, Any]
    ) -> Dict[str, str]:
        """
        åˆ›å»ºå•è¯è¯†åˆ«å¡ç‰‡ï¼ˆçœ‹å•è¯æƒ³æ„æ€ï¼‰

        Args:
            word: å•è¯
            content: å­¦ä¹ å†…å®¹

        Returns:
            Dict: å¡ç‰‡æ•°æ®
        """
        front = f"""
        <div class="card-front word-recognition">
            <h2 class="word">{escape(word)}</h2>
            <div class="hint">è¯·å›æƒ³è¿™ä¸ªå•è¯çš„æ„æ€</div>
        </div>
        """

        back = f"""
        <div class="card-back">
            <h2 class="word">{escape(word)}</h2>
            {self._format_learning_content(content)}
        </div>
        """

        return {
            "front": front.strip(),
            "back": back.strip(),
            "tags": "word-recognition toefl",
            "type": "word_recognition",
        }

    def _create_essay_translation_card(
        self, essay_data: Dict[str, Any], essay_id: int, words: List[str] = None
    ) -> Dict[str, str]:
        """
        åˆ›å»ºçŸ­æ–‡ç¿»è¯‘å¡ç‰‡ï¼ˆçœ‹çŸ­æ–‡æƒ³ç¿»è¯‘ï¼‰

        Args:
            essay_data: çŸ­æ–‡æ•°æ®
            essay_id: çŸ­æ–‡ID
            words: ç›¸å…³å•è¯åˆ—è¡¨

        Returns:
            Dict: å¡ç‰‡æ•°æ®
        """
        english_content = essay_data.get("english_content", "")
        chinese_translation = essay_data.get("chinese_translation", "")
        title = essay_data.get("title", f"Essay {essay_id}")

        # æ·»åŠ å•è¯ä¿¡æ¯
        words_info = ""
        if words:
            words_info = f"""
            <div class="essay-words">
                <strong>ç›¸å…³å•è¯:</strong> {', '.join([escape(w) for w in words])}
            </div>
            """

        front = f"""
        <div class="card-front essay-translation">
            <h3>{escape(title)}</h3>
            <div class="english-text">{escape(english_content)}</div>
            {words_info}
            <div class="hint">è¯·ç¿»è¯‘è¿™ç¯‡çŸ­æ–‡</div>
        </div>
        """

        back = f"""
        <div class="card-back">
            <h3>{escape(title)}</h3>
            <div class="translation-pair">
                <div class="english">
                    <h4>è‹±æ–‡åŸæ–‡:</h4>
                    <p>{escape(english_content)}</p>
                </div>
                <div class="chinese">
                    <h4>ä¸­æ–‡ç¿»è¯‘:</h4>
                    <p>{escape(chinese_translation)}</p>
                </div>
            </div>
            {words_info}
        </div>
        """

        return {
            "front": front.strip(),
            "back": back.strip(),
            "tags": "essay-translation toefl",
            "type": "essay_translation",
        }

    def _create_essay_reverse_card(
        self, essay_data: Dict[str, Any], essay_id: int, words: List[str] = None
    ) -> Dict[str, str]:
        """
        åˆ›å»ºçŸ­æ–‡åå‘å¡ç‰‡ï¼ˆçœ‹ç¿»è¯‘æƒ³çŸ­æ–‡ï¼‰

        Args:
            essay_data: çŸ­æ–‡æ•°æ®
            essay_id: çŸ­æ–‡ID
            words: ç›¸å…³å•è¯åˆ—è¡¨

        Returns:
            Dict: å¡ç‰‡æ•°æ®
        """
        english_content = essay_data.get("english_content", "")
        chinese_translation = essay_data.get("chinese_translation", "")
        title = essay_data.get("title", f"Essay {essay_id}")

        # æ·»åŠ å•è¯ä¿¡æ¯
        words_info = ""
        if words:
            words_info = f"""
            <div class="essay-words">
                <strong>ç›¸å…³å•è¯:</strong> {', '.join([escape(w) for w in words])}
            </div>
            """

        front = f"""
        <div class="card-front essay-reverse">
            <h3>{escape(title)}</h3>
            <div class="chinese-text">{escape(chinese_translation)}</div>
            {words_info}
            <div class="hint">è¯·æ ¹æ®ä¸­æ–‡ç¿»è¯‘å›æƒ³è‹±æ–‡åŸæ–‡</div>
        </div>
        """

        back = f"""
        <div class="card-back">
            <h3>{escape(title)}</h3>
            <div class="translation-pair">
                <div class="chinese">
                    <h4>ä¸­æ–‡ç¿»è¯‘:</h4>
                    <p>{escape(chinese_translation)}</p>
                </div>
                <div class="english">
                    <h4>è‹±æ–‡åŸæ–‡:</h4>
                    <p>{escape(english_content)}</p>
                </div>
            </div>
            {words_info}
        </div>
        """

        return {
            "front": front.strip(),
            "back": back.strip(),
            "tags": "essay-reverse toefl",
            "type": "essay_reverse",
        }

    def _create_essay_cloze_card(
        self, essay_data: Dict[str, Any], words: List[str], essay_id: int
    ) -> Dict[str, str]:
        """
        åˆ›å»ºçŸ­æ–‡å¡«ç©ºå¡ç‰‡

        Args:
            essay_data: çŸ­æ–‡æ•°æ®
            words: è¦æŒ–ç©ºçš„å•è¯åˆ—è¡¨
            essay_id: çŸ­æ–‡ID

        Returns:
            Dict: å¡ç‰‡æ•°æ®
        """
        english_content = essay_data.get("english_content", "")
        title = essay_data.get("title", f"Essay {essay_id}")

        # åˆ›å»ºæŒ–ç©ºç‰ˆæœ¬
        cloze_content = english_content
        blanked_words = []

        for word in words:
            # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æ‰¾åˆ°å•è¯ï¼ˆå¿½ç•¥å¤§å°å†™ï¼Œè€ƒè™‘è¯è¾¹ç•Œï¼‰
            pattern = r"\b" + re.escape(word) + r"\b"
            matches = list(re.finditer(pattern, cloze_content, re.IGNORECASE))

            if matches:
                # åªæ›¿æ¢ç¬¬ä¸€ä¸ªå‡ºç°çš„å•è¯
                match = matches[0]
                original_word = match.group()
                blank = f"<span class='blank'>______</span>"
                cloze_content = (
                    cloze_content[: match.start()]
                    + blank
                    + cloze_content[match.end() :]
                )
                blanked_words.append(original_word)

        front = f"""
        <div class="card-front essay-cloze">
            <h3>{escape(title)} - å¡«ç©ºç»ƒä¹ </h3>
            <div class="cloze-text">{cloze_content}</div>
            <div class="hint">è¯·å¡«å…¥ç©ºç™½å¤„çš„å•è¯</div>
            <div class="word-bank">
                <strong>è¯åº“:</strong> {', '.join([escape(w) for w in words])}
            </div>
        </div>
        """

        back = f"""
        <div class="card-back">
            <h3>{escape(title)} - å®Œæ•´ç‰ˆæœ¬</h3>
            <div class="complete-text">{escape(english_content)}</div>
            <div class="blanked-words">
                <strong>å¡«ç©ºç­”æ¡ˆ:</strong> {', '.join([escape(w) for w in blanked_words])}
            </div>
        </div>
        """

        return {
            "front": front.strip(),
            "back": back.strip(),
            "tags": "essay-cloze toefl",
            "type": "essay_cloze",
        }

    def export_words_to_anki(
        self, word_ids: Optional[List[int]] = None, output_file: str = None
    ) -> str:
        """
        å¯¼å‡ºå•è¯åˆ°Anki CSVæ ¼å¼

        Args:
            word_ids: è¦å¯¼å‡ºçš„å•è¯IDåˆ—è¡¨ï¼ŒNoneè¡¨ç¤ºå¯¼å‡ºæ‰€æœ‰æœ‰å­¦ä¹ å†…å®¹çš„å•è¯
            output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„

        Returns:
            str: å¯¼å‡ºæ–‡ä»¶è·¯å¾„
        """
        if output_file is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_file = f"anki_words_{timestamp}.csv"

        conn = self.get_database_connection()
        cursor = conn.cursor()

        try:
            # æ„å»ºæŸ¥è¯¢
            if word_ids:
                placeholders = ",".join(["?"] * len(word_ids))
                query = f"SELECT * FROM words WHERE id IN ({placeholders}) AND learn_content != '{{}}'"
                cursor.execute(query, word_ids)
            else:
                cursor.execute("SELECT * FROM words WHERE learn_content != '{}'")

            words = cursor.fetchall()

            if not words:
                raise ValueError("æ²¡æœ‰æ‰¾åˆ°å¯å¯¼å‡ºçš„å•è¯")

            # å‡†å¤‡CSVæ•°æ®
            cards = []

            for word_row in words:
                word = word_row["word"]
                try:
                    content = json.loads(word_row["learn_content"])
                except json.JSONDecodeError:
                    print(f"è·³è¿‡å•è¯ {word}ï¼Œå­¦ä¹ å†…å®¹JSONæ ¼å¼é”™è¯¯")
                    continue

                # åªåˆ›å»ºå•è¯è¯†åˆ«å¡ç‰‡
                cards.append(self._create_word_recognition_card(word, content))

            # å†™å…¥CSVæ–‡ä»¶
            with open(output_file, "w", newline="", encoding="utf-8") as csvfile:
                fieldnames = ["front", "back", "tags", "type"]
                writer = csv.DictWriter(csvfile, fieldnames=fieldnames)

                writer.writeheader()
                for card in cards:
                    writer.writerow(card)

            print(f"æˆåŠŸå¯¼å‡º {len(words)} ä¸ªå•è¯çš„ {len(cards)} å¼ å¡ç‰‡åˆ° {output_file}")
            return output_file

        finally:
            conn.close()

    def export_essays_to_anki(
        self, essay_ids: Optional[List[int]] = None, output_file: str = None
    ) -> str:
        """
        å¯¼å‡ºçŸ­æ–‡åˆ°Anki CSVæ ¼å¼

        Args:
            essay_ids: è¦å¯¼å‡ºçš„çŸ­æ–‡IDåˆ—è¡¨ï¼ŒNoneè¡¨ç¤ºå¯¼å‡ºæ‰€æœ‰çŸ­æ–‡
            output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„

        Returns:
            str: å¯¼å‡ºæ–‡ä»¶è·¯å¾„
        """
        if output_file is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_file = f"anki_essays_{timestamp}.csv"

        conn = self.get_database_connection()
        cursor = conn.cursor()

        try:
            # æ„å»ºæŸ¥è¯¢
            if essay_ids:
                placeholders = ",".join(["?"] * len(essay_ids))
                query = f"SELECT * FROM essay WHERE id IN ({placeholders})"
                cursor.execute(query, essay_ids)
            else:
                cursor.execute("SELECT * FROM essay")

            essays = cursor.fetchall()

            if not essays:
                raise ValueError("æ²¡æœ‰æ‰¾åˆ°å¯å¯¼å‡ºçš„çŸ­æ–‡")

            # å‡†å¤‡CSVæ•°æ®
            cards = []

            for essay_row in essays:
                essay_id = essay_row["id"]
                words = essay_row["words"].split(",")

                try:
                    content = json.loads(essay_row["content"])
                except json.JSONDecodeError:
                    print(f"è·³è¿‡çŸ­æ–‡ {essay_id}ï¼Œå†…å®¹JSONæ ¼å¼é”™è¯¯")
                    continue

                # ä¸ºæ¯ç¯‡çŸ­æ–‡åˆ›å»ºä¸‰ç§å¡ç‰‡
                cards.append(
                    self._create_essay_translation_card(content, essay_id, words)
                )
                cards.append(self._create_essay_reverse_card(content, essay_id, words))
                cards.append(self._create_essay_cloze_card(content, words, essay_id))

            # å†™å…¥CSVæ–‡ä»¶
            with open(output_file, "w", newline="", encoding="utf-8") as csvfile:
                fieldnames = ["front", "back", "tags", "type"]
                writer = csv.DictWriter(csvfile, fieldnames=fieldnames)

                writer.writeheader()
                for card in cards:
                    writer.writerow(card)

            print(
                f"æˆåŠŸå¯¼å‡º {len(essays)} ç¯‡çŸ­æ–‡çš„ {len(cards)} å¼ å¡ç‰‡åˆ° {output_file}"
            )
            return output_file

        finally:
            conn.close()

    def export_all_to_anki(self, output_dir: str = "anki_export") -> Dict[str, str]:
        """
        å¯¼å‡ºæ‰€æœ‰å†…å®¹åˆ°Anki

        Args:
            output_dir: è¾“å‡ºç›®å½•

        Returns:
            Dict[str, str]: å¯¼å‡ºæ–‡ä»¶è·¯å¾„å­—å…¸
        """
        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(output_dir, exist_ok=True)

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        # å¯¼å‡ºå•è¯
        words_file = os.path.join(output_dir, f"toefl_words_{timestamp}.csv")
        words_exported = self.export_words_to_anki(output_file=words_file)

        # å¯¼å‡ºçŸ­æ–‡
        essays_file = os.path.join(output_dir, f"toefl_essays_{timestamp}.csv")
        essays_exported = self.export_essays_to_anki(output_file=essays_file)

        # åˆ›å»ºCSSæ ·å¼æ–‡ä»¶
        css_file = os.path.join(output_dir, f"anki_styles_{timestamp}.css")
        self._create_css_file(css_file)

        return {"words": words_exported, "essays": essays_exported, "css": css_file}

    def export_words_to_apkg(
        self, word_ids: Optional[List[int]] = None, output_file: str = None
    ) -> str:
        """
        å¯¼å‡ºå•è¯åˆ°Anki APKGæ ¼å¼

        Args:
            word_ids: è¦å¯¼å‡ºçš„å•è¯IDåˆ—è¡¨ï¼ŒNoneè¡¨ç¤ºå¯¼å‡ºæ‰€æœ‰æœ‰å­¦ä¹ å†…å®¹çš„å•è¯
            output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„

        Returns:
            str: å¯¼å‡ºæ–‡ä»¶è·¯å¾„
        """
        if output_file is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_file = f"toefl_words_{timestamp}.apkg"

        conn = self.get_database_connection()
        cursor = conn.cursor()

        try:
            # æ„å»ºæŸ¥è¯¢
            if word_ids:
                placeholders = ",".join(["?"] * len(word_ids))
                query = f"SELECT * FROM words WHERE id IN ({placeholders}) AND learn_content != '{{}}'"
                cursor.execute(query, word_ids)
            else:
                cursor.execute("SELECT * FROM words WHERE learn_content != '{}'")

            words = cursor.fetchall()

            if not words:
                raise ValueError("æ²¡æœ‰æ‰¾åˆ°å¯å¯¼å‡ºçš„å•è¯")

            # åˆ›å»ºAnkiç‰Œç»„
            deck = genanki.Deck(
                random.randint(1 << 30, 1 << 31), "TOEFLå•è¯å­¦ä¹ "  # éšæœºdeck ID
            )

            # ä¸ºæ¯ä¸ªå•è¯åˆ›å»ºä¸‰ç§å¡ç‰‡
            for word_row in words:
                word = word_row["word"]
                try:
                    content = json.loads(word_row["learn_content"])
                except json.JSONDecodeError:
                    print(f"è·³è¿‡å•è¯ {word}ï¼Œå­¦ä¹ å†…å®¹JSONæ ¼å¼é”™è¯¯")
                    continue

                # æ ¼å¼åŒ–å­¦ä¹ å†…å®¹
                formatted_content = self._format_learning_content(content, word)

                # åªåˆ›å»ºå•è¯è¯†åˆ«å¡ç‰‡
                note1 = genanki.Note(
                    model=self.word_model,
                    fields=[word, formatted_content, "recognition"],
                    tags=["word-recognition", "toefl"],
                )
                deck.add_note(note1)

            # ç”ŸæˆAPKGæ–‡ä»¶
            package = genanki.Package(deck)
            package.write_to_file(output_file)

            print(f"æˆåŠŸå¯¼å‡º {len(words)} ä¸ªå•è¯åˆ° {output_file}")
            return output_file

        finally:
            conn.close()

    def export_essays_to_apkg(
        self, essay_ids: Optional[List[int]] = None, output_file: str = None
    ) -> str:
        """
        å¯¼å‡ºçŸ­æ–‡åˆ°Anki APKGæ ¼å¼

        Args:
            essay_ids: è¦å¯¼å‡ºçš„çŸ­æ–‡IDåˆ—è¡¨ï¼ŒNoneè¡¨ç¤ºå¯¼å‡ºæ‰€æœ‰çŸ­æ–‡
            output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„

        Returns:
            str: å¯¼å‡ºæ–‡ä»¶è·¯å¾„
        """
        if output_file is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_file = f"toefl_essays_{timestamp}.apkg"

        conn = self.get_database_connection()
        cursor = conn.cursor()

        try:
            # æ„å»ºæŸ¥è¯¢
            if essay_ids:
                placeholders = ",".join(["?"] * len(essay_ids))
                query = f"SELECT * FROM essay WHERE id IN ({placeholders})"
                cursor.execute(query, essay_ids)
            else:
                cursor.execute("SELECT * FROM essay")

            essays = cursor.fetchall()

            if not essays:
                raise ValueError("æ²¡æœ‰æ‰¾åˆ°å¯å¯¼å‡ºçš„çŸ­æ–‡")

            # åˆ›å»ºAnkiç‰Œç»„
            deck = genanki.Deck(
                random.randint(1 << 30, 1 << 31), "TOEFLçŸ­æ–‡å­¦ä¹ "  # éšæœºdeck ID
            )

            # ä¸ºæ¯ç¯‡çŸ­æ–‡åˆ›å»ºå¡ç‰‡
            for essay_row in essays:
                essay_id = essay_row["id"]
                words = essay_row["words"].split(",")

                try:
                    content = json.loads(essay_row["content"])
                except json.JSONDecodeError:
                    print(f"è·³è¿‡çŸ­æ–‡ {essay_id}ï¼Œå†…å®¹JSONæ ¼å¼é”™è¯¯")
                    continue

                english_content = content.get("english_content", "")
                chinese_translation = content.get("chinese_translation", "")
                title = content.get("title", f"Essay {essay_id}")

                # ç¿»è¯‘å¡ç‰‡
                note1 = genanki.Note(
                    model=self.essay_model,
                    fields=[
                        title,
                        english_content,
                        chinese_translation,
                        "translation",
                        ",".join(words),
                    ],
                    tags=["essay-translation", "toefl"],
                )
                deck.add_note(note1)

                # åå‘å¡ç‰‡
                note2 = genanki.Note(
                    model=self.essay_model,
                    fields=[
                        title,
                        english_content,
                        chinese_translation,
                        "reverse",
                        ",".join(words),
                    ],
                    tags=["essay-reverse", "toefl"],
                )
                deck.add_note(note2)

            # ç”ŸæˆAPKGæ–‡ä»¶
            package = genanki.Package(deck)
            package.write_to_file(output_file)

            print(f"æˆåŠŸå¯¼å‡º {len(essays)} ç¯‡çŸ­æ–‡åˆ° {output_file}")
            return output_file

        finally:
            conn.close()

    def export_all_to_apkg(self, output_dir: str = "anki_export") -> Dict[str, str]:
        """
        å¯¼å‡ºæ‰€æœ‰å†…å®¹åˆ°Anki APKGæ ¼å¼

        Args:
            output_dir: è¾“å‡ºç›®å½•

        Returns:
            Dict[str, str]: å¯¼å‡ºæ–‡ä»¶è·¯å¾„å­—å…¸
        """
        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(output_dir, exist_ok=True)

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        # å¯¼å‡ºå•è¯
        words_file = os.path.join(output_dir, f"toefl_words_{timestamp}.apkg")
        words_exported = self.export_words_to_apkg(output_file=words_file)

        # å¯¼å‡ºçŸ­æ–‡
        essays_file = os.path.join(output_dir, f"toefl_essays_{timestamp}.apkg")
        essays_exported = self.export_essays_to_apkg(output_file=essays_file)

        return {"words": words_exported, "essays": essays_exported}

    def _create_css_file(self, css_file: str) -> None:
        """åˆ›å»ºAnkiå¡ç‰‡çš„CSSæ ·å¼æ–‡ä»¶"""
        css_content = """
/* TOEFLå•è¯å­¦ä¹ å¡ç‰‡æ ·å¼ - èåˆå¸ƒå±€ç‰ˆ */

.card {
    font-family: 'Helvetica Neue', Arial, sans-serif;
    line-height: 1.5;
    margin: 15px;
    padding: 20px;
    background: #f8f9fa;
    border-radius: 8px;
    box-shadow: 0 2px 10px rgba(0,0,0,0.1);
}

/* æ­£é¢å¡ç‰‡æ ·å¼ */
.card-front {
    text-align: center;
    padding: 25px 20px;
}

.card-front h2, .card-front h3 {
    color: #2c3e50;
    margin-bottom: 15px;
}

.word {
    font-size: 2.5em;
    font-weight: bold;
    color: #3498db;
    margin-bottom: 15px;
}

.hint {
    color: #7f8c8d;
    font-style: italic;
    margin-top: 15px;
    font-size: 1.0em;
}

/* èƒŒé¢å¡ç‰‡æ ·å¼ */
.card-back {
    padding: 20px;
}

.word-content {
    background: white;
    padding: 20px;
    border-radius: 8px;
    border-left: 4px solid #3498db;
}

/* å•è¯ä¿¡æ¯å¤´éƒ¨ - éŸ³æ ‡ã€å‘éŸ³ã€è¯æ€§ä¸€è¡Œæ˜¾ç¤º */
.word-header {
    background: #f0f8ff;
    padding: 12px 18px;
    border-radius: 6px;
    margin-bottom: 15px;
    font-size: 1.0em;
    border-left: 4px solid #3498db;
    display: flex;
    align-items: center;
    flex-wrap: wrap;
    gap: 20px;
}

.phonetic-info {
    display: flex;
    align-items: center;
    gap: 10px;
}

.phonetic-text {
    font-family: 'Lucida Sans Unicode', sans-serif;
    color: #e74c3c;
    font-weight: bold;
    font-size: 1.2em;
}

.pronunciation-btn {
    background: none;
    border: none;
    font-size: 1.0em;
    cursor: pointer;
    padding: 3px 5px;
    border-radius: 3px;
    transition: background-color 0.2s;
}

.pronunciation-btn:hover {
    background-color: #e0e0e0;
}

.pronunciation-btn:active {
    background-color: #d0d0d0;
}

.pronunciation-info {
    color: #9b59b6;
    font-weight: 600;
}

.pos-info {
    color: #f39c12;
    font-weight: 700;
    background: #fff3cd;
    padding: 4px 10px;
    border-radius: 4px;
    font-size: 0.9em;
}

/* å†…å®¹åŒºåŸŸæ ·å¼ */
.word-content > div {
    margin-bottom: 12px;
    line-height: 1.6;
}

.word-content > div:last-child {
    margin-bottom: 0;
}

.translations {
    background: #f8f9fa;
    padding: 12px;
    border-radius: 5px;
    border-left: 4px solid #28a745;
}

.translations strong {
    color: #28a745;
    margin-right: 10px;
}

.phrases {
    background: #fff3cd;
    padding: 12px;
    border-radius: 5px;
    border-left: 4px solid #ffc107;
}

.phrases strong {
    color: #856404;
    margin-right: 10px;
}

.etymology {
    background: #e7f3ff;
    padding: 12px;
    border-radius: 5px;
    border-left: 4px solid #007bff;
}

.etymology strong {
    color: #004085;
    margin-right: 10px;
}

.examples {
    background: #f0f0f0;
    padding: 12px;
    border-radius: 5px;
    border-left: 4px solid #6c757d;
}

.examples strong {
    color: #495057;
    margin-right: 10px;
}

/* æ‹¼å†™å¡ç‰‡ç‰¹æ®Šæ ·å¼ */
.spelling-hint {
    background: #fff3cd;
    padding: 20px;
    border-radius: 8px;
    border: 2px dashed #ffc107;
}

.meaning {
    font-size: 1.4em;
    color: #856404;
    margin: 15px 0;
}

.spelling-answer {
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    color: white;
    padding: 20px;
    border-radius: 8px;
    text-align: center;
}

/* åå‘å¡ç‰‡æ ·å¼ */
.chinese-meaning {
    font-size: 1.6em;
    color: #e74c3c;
    padding: 20px;
    background: #fdedec;
    border-radius: 8px;
    margin: 20px 0;
}

.reverse-answer {
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    color: white;
    padding: 20px;
    border-radius: 8px;
    text-align: center;
}

/* çŸ­æ–‡å¡ç‰‡æ ·å¼ */
.english-text, .chinese-text {
    background: white;
    padding: 20px;
    border-radius: 8px;
    border-left: 4px solid #3498db;
    margin: 20px 0;
    line-height: 1.8;
}

.translation-pair {
    margin-top: 20px;
}

.translation-pair > div {
    margin-bottom: 20px;
    padding: 15px;
    border-radius: 8px;
}

.english {
    background: #e8f4fd;
    border-left: 4px solid #3498db;
}

.chinese {
    background: #fef9e7;
    border-left: 4px solid #f1c40f;
}

/* å¡«ç©ºå¡ç‰‡æ ·å¼ */
.cloze-text {
    background: white;
    padding: 20px;
    border-radius: 8px;
    border-left: 4px solid #e74c3c;
    margin: 20px 0;
    line-height: 1.8;
    font-size: 1.1em;
}

.blank {
    background: #f8d7da;
    padding: 2px 8px;
    border-radius: 4px;
    border: 2px dashed #dc3545;
    font-weight: bold;
    color: #721c24;
}

.word-bank {
    background: #d1ecf1;
    padding: 15px;
    border-radius: 8px;
    border-left: 4px solid #17a2b8;
    margin-top: 20px;
}

.complete-text {
    background: #d4edda;
    padding: 20px;
    border-radius: 8px;
    border-left: 4px solid #28a745;
    margin: 20px 0;
    line-height: 1.8;
}

.blanked-words {
    background: #fff3cd;
    padding: 15px;
    border-radius: 8px;
    border-left: 4px solid #ffc107;
    margin-top: 20px;
    font-weight: bold;
}

/* å“åº”å¼è®¾è®¡ */
@media (max-width: 768px) {
    .card {
        margin: 10px;
        padding: 15px;
    }
    
    .word {
        font-size: 2em;
    }
    
    .card-front {
        padding: 20px 15px;
    }
    
    .word-header {
        flex-direction: column;
        align-items: flex-start;
        gap: 10px;
    }
}
"""

        with open(css_file, "w", encoding="utf-8") as f:
            f.write(css_content)

        print(f"CSSæ ·å¼æ–‡ä»¶å·²åˆ›å»º: {css_file}")


def main():
    """ä¸»å‡½æ•° - æ¼”ç¤ºAnkiå¯¼å‡ºåŠŸèƒ½"""
    try:
        exporter = AnkiExporter()

        print("=== Anki APKGå¯¼å‡º ===")

        # ç›´æ¥å¯¼å‡ºAPKGæ ¼å¼
        exported_files = exporter.export_all_to_apkg()

        print(f"\n=== å¯¼å‡ºå®Œæˆ ===")
        for content_type, file_path in exported_files.items():
            print(f"{content_type}: {file_path}")

        print(f"\nğŸ“ ä½¿ç”¨è¯´æ˜:")
        print(f"1. ç›´æ¥å°†APKGæ–‡ä»¶æ‹–æ‹½åˆ°Ankiä¸­")
        print(f"2. æˆ–è€…åœ¨Ankiä¸­é€‰æ‹© 'æ–‡ä»¶' > 'å¯¼å…¥' é€‰æ‹©APKGæ–‡ä»¶")
        print(f"3. ç‚¹å‡»éŸ³æ ‡æ—è¾¹çš„ğŸ‡ºğŸ‡¸ğŸ‡¬ğŸ‡§å›¾æ ‡æ’­æ”¾å‘éŸ³")
        print(f"4. æ— éœ€å…¶ä»–é…ç½®ï¼Œæ ·å¼å·²å†…ç½®")

    except Exception as e:
        print(f"å¯¼å‡ºå¤±è´¥: {e}")


if __name__ == "__main__":
    main()
